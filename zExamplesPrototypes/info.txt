Dear Colleagues,
I hope you are fine!
Please find attached the code for Flyeralarm scraper.
1. The site has 581 product and 4508 attributes (parameters) were scraped
If you check the product page example:
https://www.flyeralarm.com/uk/shop/configurator/index/id/6175
you will see that there are "main" parameters: style, colours, Measuring line and
"popup" parameters which appear when you place mouse cursor over a parameter
value. I scraped both.
For example, for parameter "Style" list of values is the following:
    {
    "data": "17947",
    "name": "basic",
    "supplier_parameter": "",
    "supplier_product": "Champagne glasses"
    },
    {
    "data": 0,
    "name": "16.3 x 5.2 cm",
    "supplier_parameter": "Print area",
    "supplier_product": "Champagne glasses"
    }
For "main" value "supplier_parameter" is empty, for
"popup value" "supplier_parameter" is a key and "name" is value.

2. As I learned from the saxoprint code sample, the scraper just has to return
scrapy.Item subclass instances. Please check.

3. What is our strategy regarding prices? From saxoprint code example I
do not see that Items contain price field.
Anyway, the prices may (and will in most cases) depend on selected parameters
configuration. That means that, for example for Voucher booklets:
https://www.flyeralarm.com/uk/shop/configurator/index/id/5572/
we will have 2 (format) x 2 (style) x 14 (page count) x 3 (material) =
= 168 price combinations. Also, every price page contains a lot of rows.
One approach could be, to scrape all combinations nevertheless and hold them
somewhere in database backend. But this requires to run update scrapes from time
to time.
Another approach is to download prices "on demand" when user select some
combination online.
How to deal with this issue?

Best regards,
Yury
